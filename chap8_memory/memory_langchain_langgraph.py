import operator
from typing import Annotated, List, TypedDict, Union
import os
from dotenv import load_dotenv
load_dotenv()

from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END

# --- 1. Cáº¥u hÃ¬nh LLM ---

llm = ChatOllama(
    model=os.getenv("OLLAMA_MODEL"),
    base_url=os.getenv("OLLAMA_BASE_URL"),
    temperature=0
)

# --- 2. Äá»‹nh nghÄ©a State (Tráº¡ng thÃ¡i bá»™ nhá»›) ---
# State nÃ y sáº½ lÆ°u trá»¯ lá»‹ch sá»­ chat vÃ  báº£n tÃ³m táº¯t hiá»‡n táº¡i
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add] # Danh sÃ¡ch tin nháº¯n (ngáº¯n háº¡n)
    summary: str # Báº£n tÃ³m táº¯t ná»™i dung (dÃ i háº¡n)

# --- 3. Äá»‹nh nghÄ©a cÃ¡c Nodes (Chá»©c nÄƒng) ---

def call_model(state: AgentState):
    """Node nÃ y chá»‹u trÃ¡ch nhiá»‡m sinh cÃ¢u tráº£ lá»i dá»±a trÃªn tÃ³m táº¯t vÃ  chat history."""
    summary = state.get("summary", "")
    messages = state["messages"]
    
    # Náº¿u cÃ³ tÃ³m táº¯t, ta Ä‘Æ°a nÃ³ vÃ o System Prompt Ä‘á»ƒ model "nhá»›" láº¡i quÃ¡ khá»©
    if summary:
        system_message = f"Báº¡n lÃ  trá»£ lÃ½ AI há»¯u Ã­ch. ÄÃ¢y lÃ  tÃ³m táº¯t cuá»™c trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³: {summary}"
        # Trong thá»±c táº¿, báº¡n cÃ³ thá»ƒ xÃ³a bá»›t messages cÅ© á»Ÿ Ä‘Ã¢y Ä‘á»ƒ tiáº¿t kiá»‡m token
        # á» Ä‘Ã¢y ta giá»¯ láº¡i Ä‘á»ƒ demo luá»“ng cháº¡y
    else:
        system_message = "Báº¡n lÃ  trá»£ lÃ½ AI há»¯u Ã­ch."

    # Táº¡o prompt káº¿t há»£p context
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="messages"),
    ])
    
    # Gá»i Ollama
    chain = prompt | llm
    response = chain.invoke({"messages": messages})
    
    # Tráº£ vá» message má»›i Ä‘á»ƒ append vÃ o state
    return {"messages": [response]}

def summarize_conversation(state: AgentState):
    """Node nÃ y cháº¡y sau má»—i lÆ°á»£t chat Ä‘á»ƒ cáº­p nháº­t báº£n tÃ³m táº¯t."""
    summary = state.get("summary", "")
    messages = state["messages"]
    
    # Náº¿u cuá»™c há»™i thoáº¡i quÃ¡ ngáº¯n, chÆ°a cáº§n tÃ³m táº¯t láº¡i (Ä‘á»ƒ tiáº¿t kiá»‡m)
    # NhÆ°ng á»Ÿ Ä‘Ã¢y ta set > 2 tin nháº¯n lÃ  tÃ³m táº¯t luÃ´n Ä‘á»ƒ demo cho báº¡n tháº¥y
    if len(messages) > 2:
        summary_prompt = (
            "HÃ£y tÃ³m táº¯t ngáº¯n gá»n cuá»™c há»™i thoáº¡i trÃªn, bao gá»“m cáº£ tÃ³m táº¯t cÅ© (náº¿u cÃ³) "
            "vÃ  ná»™i dung má»›i trao Ä‘á»•i. Chá»‰ tráº£ vá» ná»™i dung tÃ³m táº¯t, khÃ´ng thÃªm lá»i dáº«n."
        )
        
        # Gá»i LLM Ä‘á»ƒ tÃ³m táº¯t
        response = llm.invoke(
            [
                SystemMessage(content=summary_prompt),
                HumanMessage(content=f"TÃ³m táº¯t cÅ©: {summary}\n\nNá»™i dung há»™i thoáº¡i má»›i: {messages}")
            ]
        )
        
        # Cáº­p nháº­t láº¡i summary vÃ o state
        print(f"\n--- [SYSTEM] Äang cáº­p nháº­t bá»™ nhá»› dÃ i háº¡n (Summary)... ---")
        return {"summary": response.content}
    
    return {}

# --- 4. XÃ¢y dá»±ng Graph (Luá»“ng xá»­ lÃ½) ---

workflow = StateGraph(AgentState)

# ThÃªm cÃ¡c nodes
workflow.add_node("chatbot", call_model)
workflow.add_node("summarizer", summarize_conversation)

# Äá»‹nh nghÄ©a luá»“ng Ä‘i: Start -> Chatbot -> Summarizer -> End
workflow.set_entry_point("chatbot")
workflow.add_edge("chatbot", "summarizer")
workflow.add_edge("summarizer", END)

# Compile graph
app = workflow.compile()

# --- 5. Cháº¡y thá»­ nghiá»‡m (VÃ²ng láº·p Chat) ---

def main():
    print("ğŸ¤– Bot Ä‘Ã£ sáºµn sÃ ng! (GÃµ 'exit' Ä‘á»ƒ thoÃ¡t)")
    print("Máº¹o: HÃ£y ká»ƒ tÃªn báº¡n, sá»Ÿ thÃ­ch, sau Ä‘Ã³ há»i láº¡i xem bot cÃ³ nhá»› khÃ´ng.")
    
    # Khá»Ÿi táº¡o bá»™ nhá»› rá»—ng
    current_state = {"messages": [], "summary": ""}
    
    while True:
        user_input = input("\nBáº¡n: ")
        if user_input.lower() in ["exit", "quit"]:
            break
            
        # ThÃªm tin nháº¯n user vÃ o input
        input_message = HumanMessage(content=user_input)
        current_state["messages"].append(input_message)
        
        # Cháº¡y Graph
        # stream_mode="values" Ä‘á»ƒ chÃºng ta láº¥y Ä‘Æ°á»£c state cáº­p nháº­t
        events = app.stream(current_state, stream_mode="values")
        
        for event in events:
            # Láº¥y tráº¡ng thÃ¡i cuá»‘i cÃ¹ng sau khi cháº¡y qua cÃ¡c node
            current_state = event
            
        # In cÃ¢u tráº£ lá»i cá»§a Bot (tin nháº¯n cuá»‘i cÃ¹ng trong list)
        last_msg = current_state["messages"][-1]
        if isinstance(last_msg, AIMessage):
            print(f"Bot: {last_msg.content}")
            
        # [DEBUG] In ra xem Bot Ä‘ang "nhá»›" cÃ¡i gÃ¬ trong Ä‘áº§u (Summary)
        if current_state["summary"]:
            print(f"\nğŸ” [Memory Dump]: {current_state['summary']}")

if __name__ == "__main__":
    main()